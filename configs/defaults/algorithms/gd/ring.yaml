type: 'gradient'
epochs: 60
batch_size: 32
worker_no: 0
learning_rate: 0.006
criterion: 'fisher'
optimizer: 'adam'